

\section{HCRI}

Recent trends in computer science and artificial intelligence are
moving us toward increasing dependence on human--computer
collaborative systems in which people and software each make decisions
that impact one another. Some fields, such as human--computer
interaction (HCI), focus on systems in which a human being is
primarily in control and the computer's decisions are assessed in
terms of the positive impact they have on the user. An interesting
recent example is Centaur chess
\url{http://www.huffingtonpost.com/mike-cassidy/centaur-chess-shows-power_b_6383606.html}
in which a human and machine team up to play on the same side in
chess, both making decisions, but with the machine acting as an
advisor and the human deciding which moves to actually make. Other
fields, like human computation and crowd sourcing, combine human and
machine expertise with the machine being the ultimate arbiter of
behavior and a group of human beings acting as lower level
computational components.

True collaboration, however, does not start with one participant being
assigned to a leadership role. Instead, the various agents need to
dynamically negotiate their roles and jockey for position, discovering
when and how to trust each other to move forward. A concrete example
is in the context of self-driving cars. Cars share the road with each
other and must carefully choose when to be responsive to other
vehicles and when to assert themselves to create a situation that
benefits them. Doing so makes a significant difference in the driving's
effectiveness~\cite{cunningham2015mpdm}. A related problem arises when
a self-driving wheelchair attempts to move through a group of
pedestrians~\cite{kim2016socially}. More generally, robots that
interact with people in the physical world need to navigate the
complex give-and-take of establishing mutually beneficial behaviors
where possible.

