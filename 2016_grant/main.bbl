\begin{thebibliography}{10}

\bibitem{argall09}
Brenna~D. Argall, Sonia Chernova, Manuela Veloso, and Brett Browning.
\newblock A survey of robot learning from demonstration.
\newblock {\em Robotics and Autonomous Systems}, 57(5):469--483, 2009.

\bibitem{austerweil16}
J.~L. Austerweil, S.~Brawner, A.~Greenwald, E.~Hilliard, M.~Ho, M.~L. Littman,
  J.~MacGlashan, and C.~Trimbach.
\newblock The impact of outcome preferences in a collection of non-zero-sum
  grid games.
\newblock AAAI Spring Symposium 2016 on Challenges and Opportunities in
  Multiagent Learning for the Real World, 2016.

\bibitem{babes11}
Monica Babes, Vukosi~N. Marivate, Michael~L. Littman, and Kaushik Subramanian.
\newblock Apprenticeship learning about multiple intentions.
\newblock In {\em International Conference on Machine Learning}, pages
  897--904, 2011.

\bibitem{bacharach1999}
Michael Bacharach.
\newblock Interactive team reasoning: A contribution to the theory of
  co-operation.
\newblock {\em Research in Economics}, 53(2):117--147, 1999.

\bibitem{bacharach2006beyond}
Michael Bacharach, Natalie Gold, and Robert Sugden.
\newblock {\em Beyond individual choice: teams and frames in game theory}.
\newblock Princeton University Press, 2006.

\bibitem{baker14}
C.~L. Baker and J.~B. Tenenbaum.
\newblock Modeling human plan recognition using {B}ayesian theory of mind.
\newblock In G.~Sukthankar, R.~P. Goldman, C.~Geib, D.~Pynadath, and H.~Bui,
  editors, {\em Plan, Activity and Intent Recognition: Theory and Practice},
  pages 177--204. Morgan Kaufmann, 2014.

\bibitem{Barto95}
Andrew~G. Barto, S.~J. Bradtke, and Satinder~P. Singh.
\newblock Learning to act using real-time dynamic programming.
\newblock {\em Artificial Intelligence}, 72(1):81--138, 1995.

\bibitem{becker1974nber}
Gary~S. Becker.
\newblock A theory of social interactions.
\newblock Working Paper~42, National Bureau of Economic Research, June 1974.

\bibitem{bellman57}
Richard Bellman.
\newblock {\em Dynamic Programming}.
\newblock Princeton University Press, Princeton, NJ, 1957.

\bibitem{berg1995trust}
Joyce Berg, John Dickhaut, and Kevin McCabe.
\newblock Trust, reciprocity, and social history.
\newblock {\em Games and economic behavior}, 10(1):122--142, 1995.

\bibitem{bertsekas87}
Dimitri~P. Bertsekas.
\newblock {\em Dynamic Programming: {D}eterministic and Stochastic Models}.
\newblock Prentice-Hall, Englewood Cliffs, NJ, 1987.

\bibitem{BoulariasKP2011}
A.~Boularias, J.~Kober, and J.~Peters.
\newblock Relative entropy inverse reinforcement learning.
\newblock In {\em JMLR Workshop and Conference Proceedings Volume 15: AISTATS
  2011}, pages 182--189, Cambridge, MA, USA, April 2011. MIT Press.

\bibitem{boutilier1996planning}
Craig Boutilier.
\newblock Planning, learning and coordination in multiagent decision processes.
\newblock In {\em Proceedings of the 6th conference on Theoretical aspects of
  rationality and knowledge}, pages 195--210. Morgan Kaufmann Publishers Inc.,
  1996.

\bibitem{boutilier99}
Craig Boutilier, Thomas Dean, and Steve Hanks.
\newblock Decision-theoretic planning: {S}tructural assumptions and
  computational leverage.
\newblock {\em Journal of Artificial Intelligence Research}, 11:1--94, 1999.

\bibitem{burchfiel2016distance}
Benjamin Burchfiel, Carlo Tomasi, and Ronald Parr.
\newblock Distance minimization for reward learning from scored trajectories.
\newblock In {\em Thirtieth AAAI Conference on Artificial Intelligence}, 2016.

\bibitem{Camerer:2003}
C.~F. Camerer.
\newblock {\em Behavioral Game Theory: Experiments in Strategic Interaction}.
\newblock Princeton University Press, Princeton, NJ, 2003.

\bibitem{cassidy14}
Mike Cassidy.
\newblock Centaur chess shows power of teaming human and machine.
\newblock
  http://www.huffingtonpost.com/mike-cassidy/centaur-chess-shows-power\_b\_6383606.html,
  2014.

\bibitem{charness2002understanding}
Gary Charness and Matthew Rabin.
\newblock Understanding social preferences with simple tests.
\newblock {\em Quarterly journal of Economics}, pages 817--869, 2002.

\bibitem{Choi:2012:NBI:2999134.2999169}
Jaedeug Choi and Kee-Eung Kim.
\newblock Nonparametric {B}ayesian inverse reinforcement learning for multiple
  reward functions.
\newblock In {\em Proceedings of the 25th International Conference on Neural
  Information Processing Systems}, NIPS'12, pages 305--313, USA, 2012. Curran
  Associates Inc.

\bibitem{collins95}
Gregg Collins and Louise Pryor.
\newblock Planning under uncertainty: {S}ome key issues.
\newblock In {\em Proceedings of the 14th International Joint Conference on
  Artificial Intelligence (IJCAI)}, pages 1567--1573, 1995.

\bibitem{conitzer07}
V.~Conitzer and T.~Sandholm.
\newblock {AWESOME}: {A} general multiagent learning algorithm that converges
  in self-play and learns a best response against stationary opponents.
\newblock {\em Machine Learning}, 67:23--43, 2007.

\bibitem{cournot}
A.~Cournot.
\newblock {\em Recherches sur les Principes Mathematics de la Theorie la
  Richesse}.
\newblock Hachette, 1838.

\bibitem{cunningham2015mpdm}
Alexander~G Cunningham, Enric Galceran, Ryan~M Eustice, and Edwin Olson.
\newblock {MPDM}: Multipolicy decision-making in dynamic, uncertain
  environments for autonomous driving.
\newblock In {\em 2015 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 1670--1677. IEEE, 2015.

\bibitem{daskalakis2009complexity}
Constantinos Daskalakis, Paul~W Goldberg, and Christos~H Papadimitriou.
\newblock The complexity of computing a {N}ash equilibrium.
\newblock {\em SIAM Journal on Computing}, 39(1):195--259, 2009.

\bibitem{desjardins13}
Marie desJardins and Michael~L. Littman.
\newblock {AAAI}-13 preface.
\newblock In {\em AAAI 2013}, 2013.

\bibitem{diuk2009adaptive}
Carlos Diuk, Lihong Li, and Bethany~R Leffler.
\newblock The adaptive k-meteorologists problem and its application to
  structure learning and feature selection in reinforcement learning.
\newblock In {\em Proceedings of the 26th Annual International Conference on
  Machine Learning}, pages 249--256. ACM, 2009.

\bibitem{dolgov2010path}
Dmitri Dolgov, Sebastian Thrun, Michael Montemerlo, and James Diebel.
\newblock Path planning for autonomous vehicles in unknown semi-structured
  environments.
\newblock {\em The International Journal of Robotics Research}, 29(5):485--501,
  2010.

\bibitem{fehr1999theory}
Ernst Fehr and Klaus~M Schmidt.
\newblock A theory of fairness, competition, and cooperation.
\newblock {\em Quarterly journal of Economics}, pages 817--868, 1999.

\bibitem{Fink64}
A.M. Fink.
\newblock Equilibrium in a stochastic $n$-person game.
\newblock {\em Journal of Science in Hiroshima University}, 28:89--93, 1964.

\bibitem{fud:levine}
D.~Fudenberg and D.~K. Levine.
\newblock {\em The Theory of Learning in Games}.
\newblock MIT Press, Cambridge, 1998.

\bibitem{gal04}
Kobi Gal, Avi Pfeffer, Francesca Marzo, and Barbara~J. Grosz.
\newblock Learning social preferences in games.
\newblock In {\em AAAI-04}, pages 226--231, 2004.

\bibitem{tada:jack}
T.~Goff, A.~Greenwald, E.~Hilliard, W.~Ketter, A.~Loomis, and E.~Sodomka.
\newblock {JACK}: A {J}ava auction configuration kit.
\newblock In {\em Agent-Mediated Electronic Commerce. Designing Trading
  Strategies and Mechanisms for Electronic Markets.}, volume 136 of {\em
  Lecture Notes in Business Information Processing}, pages 45--60. Springer,
  2013.

\bibitem{gopalan15}
Nakul Gopalan and Stefanie Tellex.
\newblock Modeling and solving human-robot collaborative tasks using {POMDP}s.
\newblock In {\em Robotics: Science and Systems 2015: Workshop on Model
  Learning for Human--Robot Communication}, 2015.

\bibitem{GreenwaldHall:03}
A.~Greenwald and K.~Hall.
\newblock Correlated \uppercase{$Q$}-learning.
\newblock In {\em Proceedings of the Twentieth International Conference on
  Machine Learning}, pages 242--249, 2003.

\bibitem{seqauc:nips}
A.~Greenwald, J.~Li, and E.~Sodomka.
\newblock Approximating equilibria in sequential auctions with incomplete
  information and multi-unit demand.
\newblock In {\em NIPS '12: Advances in {N}eural {I}nformation {P}rocessing
  {S}ystems}, volume~25, pages 2330--2338, December 2012.

\bibitem{efgs:rldm}
A.~Greenwald, J.~Li, E.~Sodomka, and M.~L. Littman.
\newblock Solving for best-responses in extensive-form games using
  reinforcement learning methods.
\newblock In {\em RLDM '13: Proceedings of 1st Multidisciplinary Conference
  Reinforcement Learning and Decision Making}, pages 116--120, October 2013.

\bibitem{tada:quibids}
A.~Greenwald, E.~Sodomka, E.~Stix, J.~Stix, and D.~Storch.
\newblock An empirical analysis of auctioneer profitability in {Q}uibids penny
  auctions.
\newblock In {\em Agent-Mediated Electronic Commerce. Designing Trading
  Strategies and Mechanisms for Electronic Markets.}, volume 197 of {\em
  Lecture Notes in Business Information Processing}, pages 56--68. Springer,
  2014.

\bibitem{guth1982jebo}
Werner Guth, Rolf Schmittberger, and Bernd Schwarze.
\newblock An experimental analysis of ultimatum bargaining.
\newblock {\em Journal of Economic Behavior \& Organization}, 3(4):367--388,
  1982.

\bibitem{HuWellman03}
J.~Hu and M.~Wellman.
\newblock Nash {$Q$}-learning for general-sum stochastic games.
\newblock {\em Machine Learning Research}, 4:1039--1069, 2003.

\bibitem{kaelbling98}
Leslie~Pack Kaelbling, Michael~L. Littman, and Anthony~R. Cassandra.
\newblock Planning and acting in partially observable stochastic domains.
\newblock {\em Artificial Intelligence}, 101(1--2):99--134, 1998.

\bibitem{kahneman86}
D.~Kahneman, J.~L. Knetsch, and R.~Thaler.
\newblock Fairness as a constraint on profit seeking: Entitlements in the
  market.
\newblock {\em American Economic Review}, 76:728--741, 1986.

\bibitem{kahnemanst82}
D.~Kahneman, P.~Slovic, and A.~Tversky, editors.
\newblock {\em Judgment under uncertainty: {H}euristics and biases}.
\newblock Cambridge University Press, 1982.

\bibitem{kmr:93}
Michihiro Kandori, George~J. Mailath, and Rafael Rob.
\newblock Learning, mutation, and long run equilibria in games.
\newblock {\em Econometrica}, 61(1):29--56, January 1993.

\bibitem{kearns99b}
Michael Kearns, Yishay Mansour, and Andrew~Y. Ng.
\newblock A sparse sampling algorithm for near-optimal planning in large
  {M}arkov decision processes.
\newblock In {\em Proceedings of the Sixteenth International Joint Conference
  on Artificial Intelligence (IJCAI-99)}, pages 1324--1331, 1999.

\bibitem{kim2016socially}
Beomjoon Kim and Joelle Pineau.
\newblock Socially adaptive path planning in human environments using inverse
  reinforcement learning.
\newblock {\em International Journal of Social Robotics}, 8(1):51--66, 2016.

\bibitem{kleiman16}
Max Kleiman-Weiner, Mark~K. Ho, Joseph~L. Austerweil, Michael~L. Littman, and
  Joshua~B. Tenenbaum.
\newblock Coordinate to cooperate or compete: Abstract goals and joint
  intentions in social interaction.
\newblock In {\em Proceedings of the 38th Annual Meeting of the Cognitive
  Science Society}, 2016.

\bibitem{kocsis06}
Levente Kocsis and Csaba Szepesv{\'a}ri.
\newblock Bandit based {M}onte-carlo planning.
\newblock In {\em Machine Learning: ECML 2006}, pages 282--293, 2006.

\bibitem{kolter2009regularization}
J~Zico Kolter and Andrew~Y Ng.
\newblock Regularization and feature selection in least-squares temporal
  difference learning.
\newblock In {\em Proceedings of the 26th Annual International Conference on
  Machine Learning}, pages 521--528. ACM, 2009.

\bibitem{li2009reinforcement}
Lihong Li, Jason~D Williams, and Suhrid Balakrishnan.
\newblock Reinforcement learning for dialog management using least-squares
  policy iteration and fast feature selection.
\newblock In {\em INTERSPEECH}, pages 2475--2478, 2009.

\bibitem{Littman01}
M.~Littman.
\newblock Friend or foe \uppercase{$Q$}-learning in general-sum
  \uppercase{M}arkov games.
\newblock In {\em Proceedings of Eighteenth International Conference on Machine
  Learning}, pages 322--328, June 2001.

\bibitem{littman1994markov}
Michael~L Littman.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In {\em Proceedings of the eleventh international conference on
  machine learning}, volume 157, pages 157--163, 1994.

\bibitem{littman01d}
Michael~L. Littman.
\newblock Friend-or-foe {Q}-learning in general-sum games.
\newblock In {\em Proceedings of the Eighteenth International Conference on
  Machine Learning}, pages 322--328. Morgan Kaufmann, 2001.

\bibitem{loftin14b}
Robert Loftin, James MacGlashan, Michael~L. Littman, Matthew~E. Taylor,
  David~L. Roberts, and Jeff Huang.
\newblock A strategy-aware technique for learning behaviors from discrete human
  feedback.
\newblock In {\em Proceedings of the Twenty-Eighth Association for the
  Advancement of Artificial Intelligence Conference (AAAI-14)}, 2014.

\bibitem{lopes2009active}
Manuel Lopes, Francisco Melo, and Luis Montesano.
\newblock Active learning for reward estimation in inverse reinforcement
  learning.
\newblock In {\em Machine Learning and Knowledge Discovery in Databases}, pages
  31--46. Springer, 2009.

\bibitem{macglashan15}
J.~MacGlashan, M.~Babes-Vroman, M.~desJardins, M.~Littman, S.~Muresan,
  S.~Squire, S.~Tellex, D.~Arumugam, and L.~Yang.
\newblock Grounding english commands to reward functions.
\newblock In {\em Proceedings of Robotics: Science and Systems}, 2015.

\bibitem{macglashan16}
James MacGlashan.
\newblock {BURLAP}.
\newblock http://burlap.cs.brown.edu, 2016.

\bibitem{macglashan14c}
James MacGlashan, Michael Littman, and Fiery Cushman.
\newblock Flexible theft and resolute punishment: {E}volutionary dynamics of
  social behavior among reinforcement-learning agents.
\newblock In {\em Proceedings of the Annual Conference of the Cognitive Science
  Society}, 2014.

\bibitem{macglashan15b}
James MacGlashan and Michael~L. Littman.
\newblock Between imitation and intention learning.
\newblock In {\em Proceedings of IJCAI}, 2015.

\bibitem{maes1993learning}
Pattie Maes and Robyn Kozierok.
\newblock Learning interface agents.
\newblock In {\em AAAI}, volume~93, pages 459--465, 1993.

\bibitem{poi:aamas}
B.~Mayer, E.~Sodomka, and A.~Greenwald.
\newblock The price of independence in simultaneous auctions.
\newblock In {\em AAMAS '13: Proceedings of the 12th {I}nternational
  {C}onference on {A}utonomous {A}gents and {M}ultiagent {S}ystems}, pages
  1227--1228, May 2013.

\bibitem{poi:ec}
B.~Mayer, E.~Sodomka, A.~Greenwald, and M.P. Wellman.
\newblock Accounting for price dependencies in simultaneous sealed-bid
  auctions.
\newblock In {\em EC '13: Proceedings of the 14th {ACM} {C}onference on
  {E}lectronic {C}ommerce}, pages 679--696, June 2013.

\bibitem{Michini2012}
Bernard Michini and Jonathan~P. How.
\newblock Bayesian nonparametric inverse reinforcement learning.
\newblock In Peter~A. Flach, Tijl De~Bie, and Nello Cristianini, editors, {\em
  Machine Learning and Knowledge Discovery in Databases: European Conference,
  ECML PKDD 2012, Bristol, UK, September 24-28, 2012. Proceedings, Part II},
  pages 148--163. Springer Berlin Heidelberg, Berlin, Heidelberg, 2012.

\bibitem{munoz08}
Enrique {Munoz de Cote} and Michael~L. Littman.
\newblock A polynomial-time {N}ash equilibrium algorithm for repeated
  stochastic games.
\newblock In {\em 24th Conference on Uncertainty in Artificial Intelligence
  (UAI'08)}, 2008.

\bibitem{Ng:1999:PIU:645528.657613}
Andrew~Y. Ng, Daishi Harada, and Stuart~J. Russell.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In {\em Proceedings of the Sixteenth International Conference on
  Machine Learning}, ICML '99, pages 278--287, San Francisco, CA, USA, 1999.
  Morgan Kaufmann Publishers Inc.

\bibitem{ng00}
Andrew~Y. Ng and Stuart Russell.
\newblock Algorithms for inverse reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  663--670, 2000.

\bibitem{parr2008analysis}
Ronald Parr, Lihong Li, Gavin Taylor, Christopher Painter-Wakefield, and
  Michael~L Littman.
\newblock An analysis of linear models, linear value-function approximation,
  and feature selection for reinforcement learning.
\newblock In {\em Proceedings of the 25th international conference on Machine
  learning}, pages 752--759. ACM, 2008.

\bibitem{paull16}
Liam Paull.
\newblock {What is Duckietown?}
\newblock http://duckietown.mit.edu/, 2016.

\bibitem{pomerleau93}
Dean~A. Pomerleau.
\newblock {\em Neural Network Perception for Mobile Robot Guidance}.
\newblock Kluwer Academic Publishing, 1993.

\bibitem{journals/corr/abs-1208-2112}
Qifeng Qiao and Peter~A. Beling.
\newblock Inverse reinforcement learning with {G}aussian process.
\newblock {\em CoRR}, abs/1208.2112, 2012.

\bibitem{rabin1993aer}
Matthew Rabin.
\newblock Incorporating fairness into game theory and economics.
\newblock {\em American Economic Review}, 83(5):1281--1302, 1993.

\bibitem{rabiner89}
Lawrence~R. Rabiner.
\newblock A tutorial on hidden {M}arkov models and selected applications in
  speech recognition.
\newblock {\em Proceedings of the IEEE}, 77(2):257--286, February 1989.

\bibitem{ramachandran2007bayesian}
Deepak Ramachandran and Eyal Amir.
\newblock {Bayesian Inverse Reinforcement Learning}.
\newblock {\em Proceedings of the 20th International Joint Conference on
  ArtiÔ¨Åcal Intelligence}, 51:2586--2591, 2007.

\bibitem{reddy2012inverse}
Tummalapalli~Sudhamsh Reddy, Vamsikrishna Gopikrishna, Gergely Zaruba, and
  Manfred Huber.
\newblock Inverse reinforcement learning for decentralized non-cooperative
  multiagent systems.
\newblock In {\em Systems, Man, and Cybernetics (SMC), 2012 IEEE International
  Conference on}, pages 1930--1935. IEEE, 2012.

\bibitem{RePEc:eee:ecochp:6a-64}
Peter~C. Reiss and Frank~A. Wolak.
\newblock Structural econometric modeling: Rationales and examples from
  industrial organization.
\newblock In J.J. Heckman and E.E. Leamer, editors, {\em Handbook of
  Econometrics}, volume~6A, chapter~64. Elsevier, 1 edition, 2007.

\bibitem{rumelhart86b}
D.~E. Rumelhart and J.~L. McClelland, editors.
\newblock {\em Parallel Distributed Processing: {E}xplorations in the
  Microstructures of Cognition. Volume 1: {F}oundations}.
\newblock The MIT Press, Cambridge, MA, 1986.

\bibitem{schelling1980strategy}
T.C. Schelling.
\newblock {\em The Strategy of Conflict}.
\newblock Harvard University Press, 1980.

\bibitem{searle1995construction}
John~R. Searle.
\newblock {\em The Construction of Social Reality}.
\newblock Simon and Schuster, 1995.

\bibitem{Shapley53}
L.S. Shapley.
\newblock Stochastic games.
\newblock {\em Proceedings of the National Academy of Sciences of the United
  States of America}, 39:1095--1100, 1953.

\bibitem{shiarlis2016inverse}
Kyriacos Shiarlis, Joao Messias, and Shimon Whiteson.
\newblock Inverse reinforcement learning from failure.
\newblock In {\em Proceedings of the 2016 International Conference on
  Autonomous Agents \& Multiagent Systems}, pages 1060--1068. International
  Foundation for Autonomous Agents and Multiagent Systems, 2016.

\bibitem{singh2009rewards}
Satinder Singh, Richard~L Lewis, and Andrew~G Barto.
\newblock Where do rewards come from.
\newblock In {\em Proceedings of the Annual Conference of the Cognitive Science
  Society}, pages 2601--2606, 2009.

\bibitem{sodomka13}
Eric Sodomka, Elizabeth Hilliard, Michael Littman, and Amy Greenwald.
\newblock {C}oco-{Q}: {L}earning in stochastic games with side payments.
\newblock {\em JMLR Workshop and Conference Proceedings: Proceedings of The
  30th International Conference on Machine Learning}, 28(3):1471--1479, 2013.

\bibitem{sutton99}
Richard~S. Sutton, Doina Precup, and Satinder Singh.
\newblock Between {MDP}s and semi-{MDP}s: {A} framework for temporal
  abstraction in reinforcement learning.
\newblock {\em Artificial Intelligence}, 112(1--2):181--211, 1999.

\bibitem{tomasello2005understanding}
Michael Tomasello, Malinda Carpenter, Josep Call, Tanya Behne, and Henrike
  Moll.
\newblock Understanding and sharing intentions: {The} origins of cultural
  cognition.
\newblock {\em Behavioral and Brain Sciences}, 28(05):675--691, 2005.

\bibitem{ur14}
Blase Ur, Elyse McManus, Melwyn Pak~Yong Ho, and Michael~L. Littman.
\newblock Practical trigger-action programming in the smart home.
\newblock In {\em Proceedings of the ACM SIGCHI Conference on Human Factors in
  Computing Systems (CHI)}, 2014.

\bibitem{von2009human}
Luis Von~Ahn.
\newblock Human computation.
\newblock In {\em Design Automation Conference, 2009. DAC'09. 46th ACM/IEEE},
  pages 418--419. IEEE, 2009.

\bibitem{Payne_Bettman_Johnson_1993}
Payne~John W., Bettman~James R., and Johnson~Eric J.
\newblock {\em The adaptive decision maker}.
\newblock Cambridge University Press, 1993.

\bibitem{Watkins92}
Christopher J. C.~H. Watkins and Peter Dayan.
\newblock Q-learning.
\newblock {\em Machine Learning}, 8(3):279--292, 1992.

\bibitem{tac:book}
M.~Wellman, A.~Greenwald, and P.~Stone.
\newblock {\em Autonomous Bidding Agents: Strategies and Lessons from the
  Trading Agent Competition}.
\newblock Intelligent Robotics and Autonomous Agents. MIT Press, Cambridge,
  2007.

\bibitem{simspsb:uai}
M.~P. Wellman, E.~Sodomka, and A.~Greenwald.
\newblock Self-confirming price prediction strategies for simultaneous one-shot
  auctions.
\newblock In {\em UAI '12: Proceedings of the 20th {C}onference on
  {U}ncertainty in {A}rtificial {I}ntelligence}, pages 893--902, August 2012.

\bibitem{ziebart2008maximum}
Brian~D Ziebart, Andrew~L Maas, J~Andrew Bagnell, and Anind~K Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In {\em AAAI Conference on Artificial Intelligence}, pages
  1433--1438, 2008.

\bibitem{ZGL:06}
M.~Zinkevich, A.~Greenwald, and M.~Littman.
\newblock Cyclic equilibria in {M}arkov games.
\newblock In {\em Advances in Neural Information Processing Systems 18}. {MIT}
  Press, 2006.

\end{thebibliography}
