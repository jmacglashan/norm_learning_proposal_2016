Much of human social life occurs in contexts where people must
coordinate their actions with those of others.  From party planning to
flying a rocket ship to the moon to evaluating grant proposals, groups
of people have accomplished great things by reasoning as a team and
engaging in jointly intentional behavior.  Indeed, some have argued
that, because most other animals lack the capacity to work adaptively
as cohesive unit across many domains, team reasoning may be the
hallmark of human sociality.  

We call optimal decision making, when agents hold social preferences
and employ team reasoning, socially rational behavior.  Socially
rational agents optimize a social utility function (i.e., a
representation of social preferences), which is sufficiently rich to
incorporate perceived (possibly inferred, possibly imagined) societal
benefits.  We assume that social utilities can be broken down into two
components---an objective component, which is usually a direct
function of the rules of interaction, and a subjective component,
which captures notions of distributivity and reciprocity.

Given these assumptions, we propose an iterative computational model,
in which socially-rational artificial agents construct social
preferences via repeated interactions with other, potentially human,
agents.  We contend that socially rational behavior, in which agents
optimize a learned social utility function that reflects constructed
social preferences, is a promising new avenue for orchestrating
effective collaborations between humans and machines.


Intellectual Merit: We will develop and evaluate a new inverse
reinforcement-learning algorithm that can construct social utility
functions from analysis of the successes and failures of past
interactions.

NOT DONE!!!


Broader Impact: Our approach, if successful, will help people and
machines work together more smoothly in real-world domains ranging
from robotic sous chefs to gerontechnological support for aging in
place.  We will also create and offer a new undergraduate course
called ``Social autonomous driving.''  It will contribute to the new
robotics course sequence being developed at Brown.  The emphasis of
our course will be on developing robots that drive around a test
environment, interacting smoothly with other robots and
remote-controlled cars.

We also plan to integrate our work on this project into Artemis, a
free summer program that introduces rising 9th grade girls to
computational thinking.  For example, we might have the Artemis girls
teach a robot to collaborate with them on routine tasks, such as
navigation or object search.

Our deliverables include an open-source publicly accessible toolkit
for implementing human-machine collaborative-learning tasks via
reinforcement learning. Further, we will maintain a database of
machine-machine, human-machine, and human-human experimental results
built using this toolkit, which can serve as a benchmark for future
researchers who also seek to build artifical agents that increasingly
achieve human-like behavior.
%
Finally, we expect to publish the results of the proposed research in
top-tier archival, conference proceedings and journals with high
impact factors, and to present our work at innovative, non-archival
workshops (e.g., the AAAI symposia).

