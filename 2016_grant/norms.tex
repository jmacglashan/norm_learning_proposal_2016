
The algorithms described in this proposal are designed for learning
among a small set of artificial agents, usually one or two.  We will
investigate generalization across games, so that if agents learn to
play one game well, they can also play a similar game well.
%
Likewise, we expect that agents who learn to work well with one human
can also work well with another who behaves similarly.  Similar
behavior across different people in the same environment is often
described as a \mydef{social norm} (especially when there are
sanctions for not behaving as expected)~\cite{bicchieri2005grammar}.
In other words, we seek to design and build agents capable of learning
social norms.  To evaluate the norm-learning capabilities of our
agents, we will study the evolution of norms in purely human groups to
that of hybrid human-machine groups.

%One possible direction is to have the agent learn multiple norms using reward function clustering similar to that in multiple intention IRL~\cite{babes11}, and then homogenize the clusters as the various subpopulation's behaviors converge. 

%To evaluate adaptivity in populations, we will compare the results of purely human populations with human-agent populations.

